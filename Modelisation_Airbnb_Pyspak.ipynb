{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(neighbourhood_group='Brooklyn', neighbourhood='Kensington', room_type='Private room', price=149, minimum_nights=1, number_of_reviews=9, reviews_per_month=0.21, calculated_host_listings_count=6, availability_365=365)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sc = SparkContext.getOrCreate();\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('airbnb_nyc_cleaned.csv')\n",
    "df=df.drop('latitude','longitude','host_id')\n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+---------+-----+--------------+-----------------+-----------------+------------------------------+----------------+\n",
      "|neighbourhood_group|neighbourhood|room_type|price|minimum_nights|number_of_reviews|reviews_per_month|calculated_host_listings_count|availability_365|\n",
      "+-------------------+-------------+---------+-----+--------------+-----------------+-----------------+------------------------------+----------------+\n",
      "|                  0|            0|        0|    0|             0|                0|                0|                             0|               0|\n",
      "+-------------------+-------------+---------+-----+--------------+-----------------+-----------------+------------------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "df.select(   [ F.count( F.when( F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df.columns]  ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- neighbourhood_group: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- minimum_nights: integer (nullable = true)\n",
      " |-- number_of_reviews: integer (nullable = true)\n",
      " |-- reviews_per_month: double (nullable = true)\n",
      " |-- calculated_host_listings_count: integer (nullable = true)\n",
      " |-- availability_365: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "categoricalColumns = ['neighbourhood_group', 'neighbourhood', 'room_type']\n",
    "stages = []\n",
    "\n",
    "for categoricalCol in categoricalColumns:\n",
    " \n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "    \n",
    "numericCols =['price','minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count','availability_365']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- neighbourhood_group: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- minimum_nights: integer (nullable = true)\n",
      " |-- number_of_reviews: integer (nullable = true)\n",
      " |-- reviews_per_month: double (nullable = true)\n",
      " |-- calculated_host_listings_count: integer (nullable = true)\n",
      " |-- availability_365: integer (nullable = true)\n",
      " |-- neighbourhood_groupIndex: double (nullable = false)\n",
      " |-- neighbourhood_groupclassVec: vector (nullable = true)\n",
      " |-- neighbourhoodIndex: double (nullable = false)\n",
      " |-- neighbourhoodclassVec: vector (nullable = true)\n",
      " |-- room_typeIndex: double (nullable = false)\n",
      " |-- room_typeclassVec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partialPipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = partialPipeline.fit(df)\n",
    "prep_DF = pipelineModel.transform(df)\n",
    "prep_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(232, {1: 1.0, 56: 1.0, 225: 1.0, 226: 149.0, 227: 1.0, 228: 9.0, 229: 0.21, 230: 6.0, 231: 365.0}))]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_DF.select('features').take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|price|\n",
      "+--------------------+-----+\n",
      "|(232,[1,56,225,22...|  149|\n",
      "|(232,[0,13,224,22...|  225|\n",
      "|(232,[0,6,225,226...|  150|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prep_DF = prep_DF.select(['features', 'price'])\n",
    "prep_DF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34174\n",
      "14667\n"
     ]
    }
   ],
   "source": [
    "splits = prep_DF.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "print(train_df.count())\n",
    "print(test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|price|\n",
      "+--------------------+-----+\n",
      "|(232,[0,6,224,226...|   65|\n",
      "|(232,[0,6,224,226...|   68|\n",
      "|(232,[0,6,224,226...|   69|\n",
      "|(232,[0,6,224,226...|   70|\n",
      "|(232,[0,6,224,226...|   70|\n",
      "|(232,[0,6,224,226...|   70|\n",
      "|(232,[0,6,224,226...|   70|\n",
      "|(232,[0,6,224,226...|   72|\n",
      "|(232,[0,6,224,226...|   74|\n",
      "|(232,[0,6,224,226...|   75|\n",
      "|(232,[0,6,224,226...|   75|\n",
      "|(232,[0,6,224,226...|   75|\n",
      "|(232,[0,6,224,226...|   76|\n",
      "|(232,[0,6,224,226...|   76|\n",
      "|(232,[0,6,224,226...|   77|\n",
      "|(232,[0,6,224,226...|   77|\n",
      "|(232,[0,6,224,226...|   77|\n",
      "|(232,[0,6,224,226...|   78|\n",
      "|(232,[0,6,224,226...|   78|\n",
      "|(232,[0,6,224,226...|   79|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|             price|\n",
      "+-------+------------------+\n",
      "|  count|             34174|\n",
      "|   mean| 152.0949844911336|\n",
      "| stddev|231.87775417813512|\n",
      "|    min|                10|\n",
      "|    max|             10000|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show()\n",
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|price|\n",
      "+--------------------+-----+\n",
      "|(232,[0,6,224,226...|   50|\n",
      "|(232,[0,6,224,226...|   55|\n",
      "|(232,[0,6,224,226...|   65|\n",
      "|(232,[0,6,224,226...|   67|\n",
      "|(232,[0,6,224,226...|   68|\n",
      "|(232,[0,6,224,226...|   70|\n",
      "|(232,[0,6,224,226...|   75|\n",
      "|(232,[0,6,224,226...|   75|\n",
      "|(232,[0,6,224,226...|   75|\n",
      "|(232,[0,6,224,226...|   76|\n",
      "|(232,[0,6,224,226...|   77|\n",
      "|(232,[0,6,224,226...|   78|\n",
      "|(232,[0,6,224,226...|   80|\n",
      "|(232,[0,6,224,226...|   80|\n",
      "|(232,[0,6,224,226...|   80|\n",
      "|(232,[0,6,224,226...|   80|\n",
      "|(232,[0,6,224,226...|   89|\n",
      "|(232,[0,6,224,226...|   93|\n",
      "|(232,[0,6,224,226...|   95|\n",
      "|(232,[0,6,224,226...|   95|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------------+\n",
      "|       prediction|price|            features|\n",
      "+-----------------+-----+--------------------+\n",
      "|82.87113951139625|   70|(231,[0,6,224,226...|\n",
      "|85.14834322082487|   70|(231,[0,6,224,226...|\n",
      "|79.60059355402596|   70|(231,[0,6,224,226...|\n",
      "|85.26482964210967|   70|(231,[0,6,224,226...|\n",
      "|86.61939283025036|   75|(231,[0,6,224,226...|\n",
      "+-----------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.641317\n",
      "Root Mean Squared Error (RMSE) on test data = 111.766\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Creation d'un RandomForest .\n",
    "rf = RandomForestRegressor(labelCol=\"price\", featuresCol=\"features\", maxDepth=20, maxBins=100)\n",
    "\n",
    "# Training\n",
    "rfModel = rf.fit(train_df)\n",
    "\n",
    "predictions = rfModel.transform(test_df)\n",
    "predictions.select(\"prediction\",\"price\",\"features\").show(5)\n",
    "\n",
    "# Evaluate model\n",
    "\n",
    "rf_evaluator = RegressionEvaluator(predictionCol=\"prediction\",labelCol=\"price\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % rf_evaluator.evaluate(predictions))\n",
    "\n",
    "rf_evaluator_1 = RegressionEvaluator(predictionCol=\"prediction\",labelCol=\"price\",metricName=\"rmse\")\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rf_evaluator_1.evaluate(predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree regression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|price|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|44.174886260236576|   50|(232,[0,6,224,226...|\n",
      "|44.174886260236576|   55|(232,[0,6,224,226...|\n",
      "| 67.00574393181397|   65|(232,[0,6,224,226...|\n",
      "| 67.00574393181397|   67|(232,[0,6,224,226...|\n",
      "| 67.00574393181397|   68|(232,[0,6,224,226...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.621351\n",
      "Root Mean Squared Error (RMSE) on test data = 177.178\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Creation d'un RandomForest .\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'price')\n",
    "\n",
    "# Training\n",
    "dt_model = dt.fit(train_df)\n",
    "\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_predictions.select(\"prediction\",\"price\",\"features\").show(5)\n",
    "\n",
    "# Evaluate model\n",
    "dt_evaluatorR2 = RegressionEvaluator(predictionCol=\"prediction\",labelCol=\"price\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % dt_evaluatorR2.evaluate(predictions))\n",
    "\n",
    "dt_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------------+\n",
      "|       prediction|price|            features|\n",
      "+-----------------+-----+--------------------+\n",
      "|50.13037626402358|   50|(232,[0,6,224,226...|\n",
      "|55.12399121657618|   55|(232,[0,6,224,226...|\n",
      "|65.11122112168137|   65|(232,[0,6,224,226...|\n",
      "| 67.1086671027024|   67|(232,[0,6,224,226...|\n",
      "|68.10739009321293|   68|(232,[0,6,224,226...|\n",
      "+-----------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.999998\n",
      "Root Mean Squared Error (RMSE) on test data = 0.328886\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Creation d'un  Regression lineaire\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='price', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Training\n",
    "lr_Model = lr.fit(train_df)\n",
    "\n",
    "lr_predictions = lr_Model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"price\",\"features\").show(5)\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"price\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))\n",
    "\n",
    "test_result = lr_Model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
